{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NN():\n",
    "    def __init__(self, input_layer_size = 2, hidden_layer_size = 2, output_layer_size = 2, hidden_layers = 1, lr = 0.1, epoches = 1000):\n",
    "        self.input_layer_size = input_layer_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.output_layer_size = output_layer_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.lr = lr\n",
    "        self.number_of_epoches = epoches\n",
    "\n",
    "        # initialize the weights by random numbers\n",
    "        self.W = [np.random.randn(self.input_layer_size, self.hidden_layer_size)]\n",
    "        for layer in range(hidden_layers-1):\n",
    "            self.W.append(np.random.randn(self.hidden_layer_size, self.hidden_layer_size))\n",
    "        self.W.append(np.random.randn(self.hidden_layer_size, self.output_layer_size))\n",
    "\n",
    "    def activation(self, x): # sigmoid function\n",
    "        return (1/(1+np.exp(-x)))\n",
    "    \n",
    "    def forward(self, X, less_steps = False): # forward prapogation\n",
    "        # X- input\n",
    "        input_list = X\n",
    "\n",
    "        if less_steps == False: # for full forwward propagation to get final output\n",
    "            less_steps = self.hidden_layers + 1 \n",
    "        # if a value is given to \"steps\" parameter, then we perform forward propagation to that step \n",
    "\n",
    "        for step in range(less_steps):\n",
    "            output_list = np.dot(input_list, self.W[step])\n",
    "            output_list = [self.activation(neuron) for neuron in output_list]\n",
    "            input_list = output_list\n",
    "        return input_list # since input_list = output_list at the end of the iterations and also we can use it for our loop in backward()\n",
    "    \n",
    "    def backward(self, X, y): # backward propagation\n",
    "        # X- input, y- output\n",
    "        # output_list = self.forward(X)\n",
    "        # total error = np.sum((y - output_list)**2/2)\n",
    "        hidden_layers = self.hidden_layers\n",
    "        # first back propagation for last layer\n",
    "        # error = (output)(1-output)(actual-output)\n",
    "        layer_error = np.array(self.forward(X)) * (1 - np.array(self.forward(X))) * (np.array(y) - np.array(self.forward(X)))\n",
    "        # Weight updation- W = W + alpha * (H * ((y-OP) * (OP * (1 - OP))))\n",
    "        self.W[-1] += self.lr * (np.dot(np.matrix(self.forward(X,hidden_layers)[0]).transpose(), layer_error))\n",
    "\n",
    "        # there are hidden_layers + 1 number of weight matrices, hidden_layers - 1 if we calculate first and last one out of loop\n",
    "        for step in range(2,hidden_layers+2):\n",
    "            layer_error = np.array(self.forward(X, hidden_layers+2-step)) * (1 - np.array(self.forward(X, hidden_layers+2-step))) * np.dot(self.W[-step+1],np.matrix(layer_error).transpose())\n",
    "            self.W[-step] += self.lr * (np.dot(np.matrix(self.forward(X,hidden_layers+1-step)[0]).transpose(), layer_error))\n",
    "\n",
    "\n",
    "    # training: update the weights for the given number of epoches\n",
    "    def train(self, X, y):\n",
    "        for _ in range(self.number_of_epoches):\n",
    "            self.backward(X, y)\n",
    "    \n",
    "    def total_error(self,X,y):\n",
    "        return np.sum((y - self.forward(X))**2/2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RM</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.575</td>\n",
       "      <td>4.98</td>\n",
       "      <td>15.3</td>\n",
       "      <td>504000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.421</td>\n",
       "      <td>9.14</td>\n",
       "      <td>17.8</td>\n",
       "      <td>453600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.185</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.8</td>\n",
       "      <td>728700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.998</td>\n",
       "      <td>2.94</td>\n",
       "      <td>18.7</td>\n",
       "      <td>701400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.147</td>\n",
       "      <td>5.33</td>\n",
       "      <td>18.7</td>\n",
       "      <td>760200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RM  LSTAT  PTRATIO      MEDV\n",
       "0  6.575   4.98     15.3  504000.0\n",
       "1  6.421   9.14     17.8  453600.0\n",
       "2  7.185   4.03     17.8  728700.0\n",
       "3  6.998   2.94     18.7  701400.0\n",
       "4  7.147   5.33     18.7  760200.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('housing.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['RM','LSTAT','PTRATIO']]\n",
    "y = data['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.575, 6.421, 7.185, 6.998, 7.147, 6.43 , 6.012, 6.172, 5.631,\n",
       "       6.004, 6.377, 6.009, 5.889, 5.949, 6.096, 5.834, 5.935, 5.99 ,\n",
       "       5.456, 5.727, 5.57 , 5.965, 6.142, 5.813, 5.924, 5.599, 5.813,\n",
       "       6.047, 6.495, 6.674, 5.713, 6.072, 5.95 , 5.701, 6.096, 5.933,\n",
       "       5.841, 5.85 , 5.966, 6.595, 7.024, 6.77 , 6.169, 6.211, 6.069,\n",
       "       5.682, 5.786, 6.03 , 5.399, 5.602, 5.963, 6.115, 6.511, 5.998,\n",
       "       5.888, 7.249, 6.383, 6.816, 6.145, 5.927, 5.741, 5.966, 6.456,\n",
       "       6.762, 7.104, 6.29 , 5.787, 5.878, 5.594, 5.885, 6.417, 5.961,\n",
       "       6.065, 6.245, 6.273, 6.286, 6.279, 6.14 , 6.232, 5.874, 6.727,\n",
       "       6.619, 6.302, 6.167, 6.389, 6.63 , 6.015, 6.121, 7.007, 7.079,\n",
       "       6.417, 6.405, 6.442, 6.211, 6.249, 6.625, 6.163, 8.069, 7.82 ,\n",
       "       7.416, 6.727, 6.781, 6.405, 6.137, 6.167, 5.851, 5.836, 6.127,\n",
       "       6.474, 6.229, 6.195, 6.715, 5.913, 6.092, 6.254, 5.928, 6.176,\n",
       "       6.021, 5.872, 5.731, 5.87 , 6.004, 5.961, 5.856, 5.879, 5.986,\n",
       "       5.613, 5.693, 6.431, 5.637, 6.458, 6.326, 6.372, 5.822, 5.757,\n",
       "       6.335, 5.942, 6.454, 5.857, 6.151, 6.174, 5.019, 5.403, 5.468,\n",
       "       4.903, 6.13 , 5.628, 4.926, 5.186, 5.597, 6.122, 5.404, 5.012,\n",
       "       5.709, 6.129, 6.152, 5.272, 6.943, 6.066, 6.51 , 6.25 , 5.854,\n",
       "       6.101, 5.877, 6.319, 6.402, 5.875, 5.88 , 5.572, 6.416, 5.859,\n",
       "       6.546, 6.02 , 6.315, 6.86 , 6.98 , 7.765, 6.144, 7.155, 6.563,\n",
       "       5.604, 6.153, 6.782, 6.556, 7.185, 6.951, 6.739, 7.178, 6.8  ,\n",
       "       6.604, 7.287, 7.107, 7.274, 6.975, 7.135, 6.162, 7.61 , 7.853,\n",
       "       5.891, 6.326, 5.783, 6.064, 5.344, 5.96 , 5.404, 5.807, 6.375,\n",
       "       5.412, 6.182, 5.888, 6.642, 5.951, 6.373, 6.951, 6.164, 6.879,\n",
       "       6.618, 8.266, 8.04 , 7.163, 7.686, 6.552, 5.981, 7.412, 8.337,\n",
       "       8.247, 6.726, 6.086, 6.631, 7.358, 6.481, 6.606, 6.897, 6.095,\n",
       "       6.358, 6.393, 5.593, 5.605, 6.108, 6.226, 6.433, 6.718, 6.487,\n",
       "       6.438, 6.957, 8.259, 6.108, 5.876, 7.454, 7.333, 6.842, 7.203,\n",
       "       7.52 , 8.398, 7.327, 7.206, 5.56 , 7.014, 7.47 , 5.92 , 5.856,\n",
       "       6.24 , 6.538, 7.691, 6.758, 6.854, 7.267, 6.826, 6.482, 6.812,\n",
       "       7.82 , 6.968, 7.645, 7.088, 6.453, 6.23 , 6.209, 6.315, 6.565,\n",
       "       6.861, 7.148, 6.63 , 6.127, 6.009, 6.678, 6.549, 5.79 , 6.345,\n",
       "       7.041, 6.871, 6.59 , 6.495, 6.982, 7.236, 6.616, 7.42 , 6.849,\n",
       "       6.635, 5.972, 4.973, 6.122, 6.023, 6.266, 6.567, 5.705, 5.914,\n",
       "       5.782, 6.382, 6.113, 6.426, 6.376, 6.041, 5.708, 6.415, 6.431,\n",
       "       6.312, 6.083, 5.868, 6.333, 6.144, 5.706, 6.031, 6.316, 6.31 ,\n",
       "       6.037, 5.869, 5.895, 6.059, 5.985, 5.968, 7.241, 6.54 , 6.696,\n",
       "       6.874, 6.014, 5.898, 6.516, 6.635, 6.939, 6.49 , 6.579, 5.884,\n",
       "       6.728, 5.663, 5.936, 6.212, 6.395, 6.127, 6.112, 6.398, 6.251,\n",
       "       5.362, 5.803, 3.561, 4.963, 3.863, 4.906, 4.138, 7.313, 6.649,\n",
       "       6.794, 6.38 , 6.223, 6.968, 6.545, 5.536, 5.52 , 4.368, 5.277,\n",
       "       4.652, 5.   , 4.88 , 5.39 , 5.713, 6.051, 5.036, 6.193, 5.887,\n",
       "       6.471, 6.405, 5.747, 5.453, 5.852, 5.987, 6.343, 6.404, 5.349,\n",
       "       5.531, 5.683, 4.138, 5.608, 5.617, 6.852, 5.757, 6.657, 4.628,\n",
       "       5.155, 4.519, 6.434, 6.782, 5.304, 5.957, 6.824, 6.411, 6.006,\n",
       "       5.648, 6.103, 5.565, 5.896, 5.837, 6.202, 6.193, 6.38 , 6.348,\n",
       "       6.833, 6.425, 6.436, 6.208, 6.629, 6.461, 6.152, 5.935, 5.627,\n",
       "       5.818, 6.406, 6.219, 6.485, 5.854, 6.459, 6.341, 6.251, 6.185,\n",
       "       6.417, 6.749, 6.655, 6.297, 7.393, 6.728, 6.525, 5.976, 5.936,\n",
       "       6.301, 6.081, 6.701, 6.376, 6.317, 6.513, 6.209, 5.759, 5.952,\n",
       "       6.003, 5.926, 5.713, 6.167, 6.229, 6.437, 6.98 , 5.427, 6.162,\n",
       "       6.484, 5.304, 6.185, 6.229, 6.242, 6.75 , 7.061, 5.762, 5.871,\n",
       "       6.312, 6.114, 5.905, 5.454, 5.414, 5.093, 5.983, 5.983, 5.707,\n",
       "       5.926, 5.67 , 5.39 , 5.794, 6.019, 5.569, 6.027, 6.593, 6.12 ,\n",
       "       6.976, 6.794, 6.03 ])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data['RM'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
