{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Cancer Types Using Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries and functions\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "train = pd.read_csv('data/data_train.csv')\n",
    "test = pd.read_csv('data/data_test.csv')\n",
    "actual = pd.read_csv('data/actual.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Data Description "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset comprises gene expression data stored in RES format, a commonly used format for gene pattern data ([more about RES format here](https://www.genepattern.org/file-formats-guide#RES)). The dataset encompasses 7129 distinct gene features, with columns representing various samples.\n",
    "\n",
    "For each gene, the numerical entries denote its expression levels within a given sample. Additionally, an accompanying `call` column indicates whether the gene is classified as Absent (A), Marginal (M), or Present (P) in that particular sample.\n",
    "\n",
    "The dataset is divided into two files:\n",
    "\n",
    "- `train`: Contains data from 38 samples.\n",
    "- `test`: Contains data from 34 samples.\n",
    "\n",
    "This totals to 72 samples in the entire dataset.\n",
    "\n",
    "### Cancer Types\n",
    "\n",
    "The dataset focuses on two types of cancer:\n",
    "\n",
    "1. **Acute Myeloid Leukemia (AML):** AML affects myeloid cells, which are responsible for generating certain types of white blood cells.\n",
    "\n",
    "2. **Acute Lymphocytic Leukemia (ALL):** ALL is a form of cancer that impacts lymphocytes, a crucial type of white blood cell involved in the immune response. ([source](https://www.healthline.com/health/leukemia/aml-vs-all))\n",
    "\n",
    "### Patient Information\n",
    "\n",
    "The `actual` file provides information about individual patients, including their unique identifiers and the specific type of cancer they have been diagnosed with (AML or ALL).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7129, 78) (7129, 70)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene Description</th>\n",
       "      <th>Gene Accession Number</th>\n",
       "      <th>1</th>\n",
       "      <th>call</th>\n",
       "      <th>2</th>\n",
       "      <th>call.1</th>\n",
       "      <th>3</th>\n",
       "      <th>call.2</th>\n",
       "      <th>4</th>\n",
       "      <th>call.3</th>\n",
       "      <th>...</th>\n",
       "      <th>29</th>\n",
       "      <th>call.33</th>\n",
       "      <th>30</th>\n",
       "      <th>call.34</th>\n",
       "      <th>31</th>\n",
       "      <th>call.35</th>\n",
       "      <th>32</th>\n",
       "      <th>call.36</th>\n",
       "      <th>33</th>\n",
       "      <th>call.37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFFX-BioB-5_at (endogenous control)</td>\n",
       "      <td>AFFX-BioB-5_at</td>\n",
       "      <td>-214</td>\n",
       "      <td>A</td>\n",
       "      <td>-139</td>\n",
       "      <td>A</td>\n",
       "      <td>-76</td>\n",
       "      <td>A</td>\n",
       "      <td>-135</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>A</td>\n",
       "      <td>-318</td>\n",
       "      <td>A</td>\n",
       "      <td>-32</td>\n",
       "      <td>A</td>\n",
       "      <td>-124</td>\n",
       "      <td>A</td>\n",
       "      <td>-135</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFFX-BioB-M_at (endogenous control)</td>\n",
       "      <td>AFFX-BioB-M_at</td>\n",
       "      <td>-153</td>\n",
       "      <td>A</td>\n",
       "      <td>-73</td>\n",
       "      <td>A</td>\n",
       "      <td>-49</td>\n",
       "      <td>A</td>\n",
       "      <td>-114</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>-114</td>\n",
       "      <td>A</td>\n",
       "      <td>-192</td>\n",
       "      <td>A</td>\n",
       "      <td>-49</td>\n",
       "      <td>A</td>\n",
       "      <td>-79</td>\n",
       "      <td>A</td>\n",
       "      <td>-186</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFFX-BioB-3_at (endogenous control)</td>\n",
       "      <td>AFFX-BioB-3_at</td>\n",
       "      <td>-58</td>\n",
       "      <td>A</td>\n",
       "      <td>-1</td>\n",
       "      <td>A</td>\n",
       "      <td>-307</td>\n",
       "      <td>A</td>\n",
       "      <td>265</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>-95</td>\n",
       "      <td>A</td>\n",
       "      <td>49</td>\n",
       "      <td>A</td>\n",
       "      <td>-37</td>\n",
       "      <td>A</td>\n",
       "      <td>-70</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFFX-BioC-5_at (endogenous control)</td>\n",
       "      <td>AFFX-BioC-5_at</td>\n",
       "      <td>88</td>\n",
       "      <td>A</td>\n",
       "      <td>283</td>\n",
       "      <td>A</td>\n",
       "      <td>309</td>\n",
       "      <td>A</td>\n",
       "      <td>12</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>193</td>\n",
       "      <td>A</td>\n",
       "      <td>312</td>\n",
       "      <td>A</td>\n",
       "      <td>230</td>\n",
       "      <td>P</td>\n",
       "      <td>330</td>\n",
       "      <td>A</td>\n",
       "      <td>337</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFFX-BioC-3_at (endogenous control)</td>\n",
       "      <td>AFFX-BioC-3_at</td>\n",
       "      <td>-295</td>\n",
       "      <td>A</td>\n",
       "      <td>-264</td>\n",
       "      <td>A</td>\n",
       "      <td>-376</td>\n",
       "      <td>A</td>\n",
       "      <td>-419</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>-51</td>\n",
       "      <td>A</td>\n",
       "      <td>-139</td>\n",
       "      <td>A</td>\n",
       "      <td>-367</td>\n",
       "      <td>A</td>\n",
       "      <td>-188</td>\n",
       "      <td>A</td>\n",
       "      <td>-407</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Gene Description Gene Accession Number    1 call    2  \\\n",
       "0  AFFX-BioB-5_at (endogenous control)        AFFX-BioB-5_at -214    A -139   \n",
       "1  AFFX-BioB-M_at (endogenous control)        AFFX-BioB-M_at -153    A  -73   \n",
       "2  AFFX-BioB-3_at (endogenous control)        AFFX-BioB-3_at  -58    A   -1   \n",
       "3  AFFX-BioC-5_at (endogenous control)        AFFX-BioC-5_at   88    A  283   \n",
       "4  AFFX-BioC-3_at (endogenous control)        AFFX-BioC-3_at -295    A -264   \n",
       "\n",
       "  call.1    3 call.2    4 call.3  ...   29 call.33   30 call.34   31 call.35  \\\n",
       "0      A  -76      A -135      A  ...   15       A -318       A  -32       A   \n",
       "1      A  -49      A -114      A  ... -114       A -192       A  -49       A   \n",
       "2      A -307      A  265      A  ...    2       A  -95       A   49       A   \n",
       "3      A  309      A   12      A  ...  193       A  312       A  230       P   \n",
       "4      A -376      A -419      A  ...  -51       A -139       A -367       A   \n",
       "\n",
       "    32 call.36   33 call.37  \n",
       "0 -124       A -135       A  \n",
       "1  -79       A -186       A  \n",
       "2  -37       A  -70       A  \n",
       "3  330       A  337       A  \n",
       "4 -188       A -407       A  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>cancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient cancer\n",
       "0        1    ALL\n",
       "1        2    ALL\n",
       "2        3    ALL\n",
       "3        4    ALL\n",
       "4        5    ALL"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ALL', 'AML'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual.cancer.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the call columns as they are not required\n",
    "required_train_columns = ['Gene Accession Number']\n",
    "for i in range(1,39):\n",
    "    required_train_columns.append(str(i))\n",
    "# transposing the dataframe to have rows as samples\n",
    "train = train[required_train_columns].set_index('Gene Accession Number').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the call columns as they are not required\n",
    "required_test_columns = ['Gene Accession Number']\n",
    "for i in range(39,73):\n",
    "    required_test_columns.append(str(i))\n",
    "# transposing the dataframe to have rows as samples    \n",
    "test = test[required_test_columns].set_index('Gene Accession Number').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the target value column, i.e., cancer type from 'actual' file\n",
    "train['target'] = list(actual.cancer.iloc[:38])\n",
    "\n",
    "test['target'] = list(actual.cancer.iloc[38:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining train and test sets clearly to easily use in models\n",
    "X_train = train[train.columns[:-1]]\n",
    "y_train = train.target\n",
    "X_test = test[test.columns[:-1]]\n",
    "y_test = test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model (with different kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9705882352941176\n"
     ]
    }
   ],
   "source": [
    "# radial basis function (rbf) kernel\n",
    "svcrbf = SVC(kernel='rbf', C=10)\n",
    "svcrbf.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy: ', svcrbf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9705882352941176\n"
     ]
    }
   ],
   "source": [
    "# linear kernel\n",
    "svclin = SVC(kernel='linear')\n",
    "svclin.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy: ', svclin.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9705882352941176\n"
     ]
    }
   ],
   "source": [
    "# polynomial kernel\n",
    "svcpoly = SVC(kernel='poly', C=10)\n",
    "svcpoly.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy: ', svcpoly.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9117647058823529\n"
     ]
    }
   ],
   "source": [
    "# sigmoid kernel\n",
    "svcsig = SVC(kernel='sigmoid', C=10)\n",
    "svcsig.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy: ', svcsig.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8529411764705882\n"
     ]
    }
   ],
   "source": [
    "rfmodel = RandomForestClassifier(random_state=42)\n",
    "rfmodel.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy: ', rfmodel.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant'}\n",
      "Test Accuracy: 0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "    'alpha' : [0.0001, 0.001, 0.01],\n",
    "    'learning_rate' : ['constant', 'invscaling', 'adaptive']\n",
    "}\n",
    "\n",
    "# Initialize the MLPClassifier\n",
    "nnmodel = MLPClassifier(random_state=42, early_stopping=True)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(nnmodel, param_grid, cv=3, n_jobs=-1, scoring=accuracy_score)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = best_estimator.score(X_test, y_test)\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Result Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment the lines to store files from the predictions of the above-mentioned models on the test data\n",
    "# # The outputs generated can be found in 'output' folder [Note that the following code doesn't store it in that folder]\n",
    "# pd.DataFrame({'target':y_test,'prediction':svcrbf.predict(X_test)}).to_csv('svm_rcf_preds.csv')\n",
    "# pd.DataFrame({'target':y_test,'prediction':svclin.predict(X_test)}).to_csv('svm_lin_preds.csv')\n",
    "# pd.DataFrame({'target':y_test,'prediction':svcpoly.predict(X_test)}).to_csv('svm_poly_preds.csv')\n",
    "# pd.DataFrame({'target':y_test,'prediction':svcsig.predict(X_test)}).to_csv('svm_sig_preds.csv')\n",
    "# pd.DataFrame({'target':y_test,'prediction':rfmodel.predict(X_test)}).to_csv('random_forest_preds.csv')\n",
    "# pd.DataFrame({'target':y_test,'prediction':nnmodel.predict(X_test)}).to_csv('neural_networks_preds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM's role in cancer type prediction\n",
    "\n",
    "In our study, we leveraged Support Vector Machines (SVMs) to predict cancer types based on RES format gene data. SVMs proved invaluable in identifying the optimal decision boundary, effectively separating different cancer types by harnessing genetic information.\n",
    "\n",
    "The versatility of SVMs was demonstrated through the use of various kernels:\n",
    "\n",
    "- **Linear Kernel**: Effective for linearly separable data.\n",
    "- **RBF Kernel**: Excelled in capturing non-linear relationships in genetic data.\n",
    "- **Polynomial Kernel**: Valuable for representing polynomial decision boundaries.\n",
    "\n",
    "Each kernel was thoroughly evaluated. The linear, RBF, and polynomial kernels achieved an impressive accuracy of approximately 97.06%. This underscores the robustness of SVMs in distinguishing between AML and ALL cases based on the provided gene data.\n",
    "\n",
    "Notably, the sigmoid kernel, while still performing well, achieved a slightly lower accuracy of approximately 91.18%. This indicates that, for our specific dataset and problem, the sigmoid kernel might not be as well-suited as the other kernels. This emphasizes the critical importance of selecting the most appropriate kernel tailored to the data's characteristics.\n",
    "\n",
    "### Handling High-Dimensional Data\n",
    "\n",
    "SVMs excel in scenarios with numerous features, as seen in our study with 7129 features. Here's how SVMs handled this high-dimensional data:\n",
    "\n",
    "1. **Feature Selection**: SVMs find optimal decision boundaries in high-dimensional spaces, crucial for distinguishing cancer types based on genetic data.\n",
    "\n",
    "2. **Margin Maximization**: They maximize the margin, enhancing generalization to new data points.\n",
    "\n",
    "3. **Kernel Trick for Complexity**: Various kernels handle non-linearities in genetic data effectively.\n",
    "\n",
    "4. **Identifying Important Features**: SVMs pinpoint crucial genes for accurate predictions.\n",
    "\n",
    "5. **Effective Generalization**: Despite high dimensionality, SVMs generalize well to new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Regression Analysis\n",
    "\n",
    "In our study, we used neural network regression to predict cancer types from gene data. This approach is crucial for the following reasons:\n",
    "\n",
    "- **Complex Relationship Modeling**: Neural networks excel at capturing intricate, non-linear relationships in high-dimensional genetic data. This uncovers subtle patterns not easily discernible with traditional methods.\n",
    "\n",
    "- **Feature Extraction and Abstraction**: Neural networks automatically extract relevant features, potentially identifying critical genetic markers for cancer classification.\n",
    "\n",
    "- **Adaptability to High-Dimensional Data**: Neural networks handle large feature sets, as demonstrated with our 7129-feature gene dataset.\n",
    "\n",
    "We also conducted a grid search to optimize the neural network parameters:\n",
    "\n",
    "- **Grid Search Process**:\n",
    "\n",
    "  This process systematically explores a specified hyperparameter grid to find the best-performing combination. Key hyperparameters for neural networks include hidden layers, neurons per layer, activation functions, and regularization terms.\n",
    "\n",
    "  Grid search fine-tunes the model, preventing overfitting and underfitting. Our analysis resulted in an approximately 94.12% accuracy, indicating effective hyperparameter selection for accurate cancer type predictions using the provided gene dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison\n",
    "\n",
    "We evaluated three models for cancer type prediction based on gene data: Neural Networks, Support Vector Machines (SVM), and Random Forest.\n",
    "\n",
    "- **Neural Network Accuracy**: ~94.12%\n",
    "- **SVM Accuracy**: ~97.06%\n",
    "- **Random Forest Accuracy**: ~85.29% (no hyperparameter tuning)\n",
    "\n",
    "## Model Strengths:\n",
    "\n",
    "- **SVM**:\n",
    "  - Effective in high-dimensional spaces.\n",
    "  - Handles linear and non-linear relationships.\n",
    "  - Robust against overfitting.\n",
    "\n",
    "- **Neural Networks**:\n",
    "  - Exceptional at capturing complex relationships.\n",
    "  - Automatically extracts relevant features.\n",
    "\n",
    "- **Random Forest**:\n",
    "  - Handles high-dimensional data effectively.\n",
    "  - Provides feature importances.\n",
    "\n",
    "## Model Weaknesses:\n",
    "\n",
    "- **SVM**:\n",
    "  - Can be computationally expensive.\n",
    "  - Sensitive to kernel and hyperparameters.\n",
    "\n",
    "- **Neural Networks**:\n",
    "  - Prone to overfitting with insufficient data.\n",
    "  - Computationally intensive.\n",
    "\n",
    "- **Random Forest**:\n",
    "  - Can be computationally expensive with many trees.\n",
    "  - Limited in capturing complex relationships.\n",
    "\n",
    "## Model Selection:\n",
    "\n",
    "Given our context, the SVM model with an accuracy of ~97.06% is the most suitable. It excels in high-dimensional spaces and generalizes well. While neural networks performed well, they may be computationally intensive. Random Forest, with hyperparameter tuning, could be further optimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "## Broader Implications of Accurate Cancer Type Prediction\n",
    "\n",
    "Accurate cancer type prediction holds immense significance in clinical practice and medical research. It can:\n",
    "\n",
    "- **Guide Treatment Strategies**: Precise cancer typing informs treatment decisions, enabling tailored therapies for better patient outcomes.\n",
    "\n",
    "- **Facilitate Early Detection**: Early identification of cancer types can lead to more effective and less invasive interventions.\n",
    "\n",
    "- **Enable Personalized Medicine**: Understanding the specific genetic characteristics of a tumor allows for targeted treatments, minimizing side effects.\n",
    "\n",
    "- **Advance Research and Drug Development**: Accurate classification aids in identifying potential drug targets and developing new therapies.\n",
    "\n",
    "## Real-World Applications\n",
    "\n",
    "The models' performance has practical applications:\n",
    "\n",
    "- **Clinical Settings**: Doctors can use these models to support their diagnostic process, providing an additional layer of confidence in cancer typing.\n",
    "\n",
    "- **Research Institutes**: Scientists can employ these models for genetic studies, accelerating discoveries in oncology.\n",
    "\n",
    "- **Drug Development**: Pharmaceutical companies can use accurate cancer typing to streamline clinical trials and develop more effective drugs.\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "## Summary of Findings\n",
    "\n",
    "After careful evaluation, the Support Vector Machine (SVM) emerged as the best-performing model with an accuracy of approximately 97.06%. Its effectiveness in high-dimensional spaces and robust generalization makes it the optimal choice for accurate cancer type prediction.\n",
    "\n",
    "## Importance of Model Selection and Tuning\n",
    "\n",
    "This study underscores the critical role of thoughtful model selection and parameter tuning in machine learning. The SVM's success highlights the importance of matching the model to the data's characteristics. Additionally, parameter optimization ensures the model is fine-tuned for optimal performance.\n",
    "\n",
    "In the context of cancer prediction, these considerations are paramount for achieving clinically relevant results and advancing cancer research and treatment.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
